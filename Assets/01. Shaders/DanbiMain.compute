#pragma kernel Dome_Reflector_Cube_Panorama
// #pragma kernel Dome_Reflector_Cylinder_Panorama

static const float PI = 3.14159265f;
static const float EPS = 1e-8;
static const float BIG_FLOAT = 1e+8;

float4x4 _CameraToWorldMat;
float3 _CameraViewDirectionInUnitySpace; // the z axis of the camera
float4x4 _Projection;
float4x4 _CameraInverseProjection;
float2 _PixelOffset;

Texture2D<float4> _PanoramaImage;
SamplerState sampler_PanoramaImage;

int _MaxBounce;
RWTexture2D<float4> _DistortedImage;

RWStructuredBuffer<float> _Dbg_direct;
bool bWritten = false;
RWStructuredBuffer<float4> dbg_centerOfPanoBuf;
RWStructuredBuffer<float4> dbg_hitInfoBuf;
RWStructuredBuffer<float3> dbg_rayLengthBuf;

//
// Panorama Coordinates Mapping
//

int _isPanoramaTex;
float4 _centerOfPanoramaMesh;

struct Ray 
{
  float3 origin;
  float3 direction;
  float3 localDirectionInCamera;
  float3 energy;
};

struct RayHit 
{
  float3 position; // hit position on the surface.
  float3 xyzFromCenterOfPanoramaMesh; // TODO: this is the local position of the hit point relative to the center of the mesh
  float2 uvInTriangle; // relative barycentric coordinates of the hit position.
  float3x2 vertexUVs;
  float distance;
  float3 normal; // normal at the ray hit position.
  float3 specular;
  float3 emission;
};

/*
* All geometries
*/
StructuredBuffer<float3> _Vertices;
StructuredBuffer<int> _Indices;
StructuredBuffer<float2> _Texcoords;

/*
* Undistortion methods
*/

bool _UseUndistortion;
int _UndistortionMethod;
int counter;
float _IterativeSafeCounter;
float _IterativeThreshold;
float _NewtownThreshold;

/*
* Camera Internal Parameters
*/

struct CameraInternalData 
{
  float RadialCoefficientX;
  float RadialCoefficientY;
  float RadialCoefficientZ;
  float TangentialCoefficientX;
  float TangentialCoefficientY;
  float PrincipalPointX;
  float PrincipalPointY;
  float FocalLengthX;
  float FocalLengthY;
  float SkewCoefficient; // Rarely used recently since modern cameras have got better.
};
StructuredBuffer<CameraInternalData> _CameraInternalData;

/*
* Panorama 
*/
struct PanoramaData
{
  float high;
  float low;  
  float4x4 localToWorld;  
  float4x4 worldToLocal;
  int indexCount;
  int indexOffset;
  float3 specular;
  float3 emission;
};
StructuredBuffer<PanoramaData> _PanoramaData;

/*
* Halfsphere
*/
struct DomeData 
{  
  float distance;
  float height;
  float radius;
  float maskingRatio;
  float4x4 localToWorld;
  int indexCount;  
  int indexOffset;
  float3 specular;
  float3 emission;
};
StructuredBuffer<DomeData> _DomeData;

//
// Ray, RayHit
//
Ray CreateRay(float3 origin, float3 direction, float3 localDirectionInCamera);
Ray CreateCameraRay(float2 undistortedNDC);
RayHit CreateRayHit();

// Collision
RayHit Collsion(Ray ray, int bounce, DomeData shape, PanoramaData panorama);
// Shade
float3 Shade(inout Ray ray, RayHit resHit);
float3 PanoramaShade(inout Ray ray, RayHit resHit);

// Intersect
bool IntersectTriangle_MT97(Ray ray, float3 vtx0, float3 vtx1, float3 vtx2, out float t, out float u, out float v);
void IntersectDome(Ray ray, inout RayHit resHit, DomeData shape);
void IntersectMeshPanorama(Ray ray, inout RayHit bestHit, PanoramaData data);

float2 ToPanoramaUV(float3 xyz);

float2 normalize(float x_u, float y_u, in CameraInternalData data);
float2 denormalize(float x_u, float y_u, in CameraInternalData data);
float2 distort_normalized(float x_nu, float y_nu, in CameraInternalData data);
float2 undistortNDC_newton(float2 points, in CameraInternalData data);
float2 undistortNDC_iterative(float2 points, in CameraInternalData data);
float2 undistortNDC_direct(float2 points, CameraInternalData data);

float2 calibrate(float2 coords, CameraInternalData dat);

float2 ToRadialCoords(float3 coords);
float2 ToCubeCoords(float3 coords, float3 layout, float4 edgeSize, float4 faceXCoordsLayouts, float4 faceYCoordsLayouts, float4 faceZCoordsLayout);

[numthreads(8, 8, 1)]
void Dome_Reflector_Cube_Panorama(uint3 id : SV_DispatchThreadID) 
{  
  // float3 CameraPosInWorld = mul(_CameraToWorldMat, float4(0, 0, 0, 1)).xyz;
  // float3 CameraViewDirection = -float3(_CameraToWorldMat[0][2], _CameraToWorldMat[1][2], _CameraToWorldMat[0][2]);
  
  uint width = 0, height = 0;
  _DistortedImage.GetDimensions(width, height);
  
  // float2 undistorted_ndc = (float2)0;
  // float2 undistorted_pixelCoords = (float2)0;
  
  // if (!_UseUndistortion)
  // { 
  //   undistorted_ndc = float2(
  //     ((float)id.x + _PixelOffset.x) / (float)width * 2.0 - 1.0, 
  //     ((float)id.y + _PixelOffset.y) / (float)height * 2.0 - 1.0
  //   );
  // } 
  // else 
  // { 
  //   switch (_UndistortionMethod)
  //   { 
  //     case 0: 
  //     undistorted_pixelCoords = undistortNDC_direct((float2)id.xy, _CameraInternalData[0]);
  //     break; 
 
  //     // case 1: 
  //     // undistorted_pixelCoords = undistortNDC_iterative((float2)id.xy, _CameraInternalData[0]); 
  //     // break; 
 
  //     // case 2: 
  //     // undistorted_pixelCoords = undistortNDC_newton((float2)id.xy, _CameraInternalData[0]); 
  //     // break;
  //   }

	//   // Transform pixel to [-1,1] range 
  //   undistorted_ndc = float2(undistorted_pixelCoords.x + _PixelOffset.x / (float)width * 2.0 - 1.0,
  //                            undistorted_pixelCoords.y + _PixelOffset.y / (float)height * 2.0 - 1.0);
  // }
  // float2 undistorted_pixelCoords = undistortNDC_direct((float2)id.xy, _CameraInternalData[0]);
  // float2 undistorted_ndc = float2(undistorted_pixelCoords.x + _PixelOffset.x / (float)width * 2.0 - 1.0,
  //                                 undistorted_pixelCoords.y + _PixelOffset.y / (float)height * 2.0 - 1.0);  
  // dbg_rayLengthBuf[0] = float3(_isPanoramaTex, _isPanoramaTex, _isPanoramaTex);

  float2 undistorted_ndc = float2(
      ((float)id.x + _PixelOffset.x) / (float)width * 2.0 - 1.0, 
      ((float)id.y + _PixelOffset.y) / (float)height * 2.0 - 1.0
    );
  Ray ray = CreateCameraRay(undistorted_ndc);
  RayHit resHit = (RayHit)0;
  
  // Black color is default.
  float3 totalCol = (float3)0;
  
  for (int i = 0; i < _MaxBounce; ++i) 
  {
    resHit = Collsion(ray, i, _DomeData[0], _PanoramaData[0]);
    
    if (resHit.distance >= BIG_FLOAT)
      break;      

    if (_isPanoramaTex == 0)
    {      
      totalCol += Shade(ray, resHit) * ray.energy;
    }
    else
    {
      totalCol += PanoramaShade(ray, resHit) * ray.energy;
    }
    
    if (!any(ray.energy)) 
      break;
  }
  //The screenspace origin is at the bottom left. Only the GUI space has it's origin at the top left. 
	//(0, 0) is the bottom left corner in pixel coordinates, and the top-right corner is (Screen.width, Screen.height). 
  _DistortedImage[id.xy] = float4(totalCol, 1);
}

//https://docs.microsoft.com/en-us/windows/win32/direct3dhlsl/sv-dispatchthreadid#:~:text=Indices%20for%20which%20combined%20thread%20and%20thread%20group,across%20the%20range%20specified%20in%20Dispatch%20and%20numthreads. 
//
//SV_DispatchThreadID is the sum of SV_GroupID* numthreads and GroupThreadID. 
//It varies across the range specified in Dispatch and numthreads. 
//For example if Dispatch(2, 2, 2) is called on a compute shader with numthreads(3, 3, 3) 
//SV_DispatchThreadID will have a range of 0..5 for each dimension. 
// id, a SV_DisptachThreadID, ranges over the screen width and height. 
// [numthreads(8, 8, 1)]
// void Dome_Reflector_Cylinder_Panorama(uint3 id : SV_DispatchThreadID) 
// {  
//   //float3 CameraPosInWorld = mul(_CameraToWorldMat, float4(0, 0, 0, 1)).xyz;
//   //float3 CameraViewDirection = -float3(_CameraToWorldMat[0][2], _CameraToWorldMat[1][2], _CameraToWorldMat[0][2]);

//   //dbg_centerOfPanoBuf[0] = _centerOfPanoramaMesh;   
//   uint width = 0, height = 0;
//   _DistortedImage.GetDimensions(width, height);

//   //https://www.gamasutra.com/blogs/DavidKuri/20180504/317575/GPU_Ray_Tracing_in_Unity__Part_1.php 
// 	//https://www.gamedev.net/tutorials/programming/graphics/ray-tracing-part-1-r3556/ 
// 	//https://www.scratchapixel.com/lessons/3d-basic-rendering/ray-tracing-generating-camera-rays/generating-camera-rays 
 
// 	// (u,v, z) = ( w/h (2*x/w -1), 2*y/h -1, 1/tan(theta/2) ) 
//   float2 undistorted_ndc = float2(
//     ((float)id.x + _PixelOffset.x) / (float)width * 2.0 - 1.0,
//     ((float)id.y + _PixelOffset.y) / (float)height * 2.0 - 1.0
//   );
  
//   Ray ray = CreateCameraRay(undistorted_ndc);  
//   RayHit resHit = (RayHit)0;
  
//   // Black color is default.
//   float3 totalCol = (float3)0;
  
//   for (int i = 0; i < _MaxBounce; ++i) 
//   {
//     resHit = Collsion(ray, i, _DomeData[0], _PanoramaData[0]);
    
//     if (resHit.distance >= BIG_FLOAT)
//       break;
        
    
    
//     if (!any(ray.energy)) 
//       break;
//   }
//   _DistortedImage[id.xy] = float4(totalCol, 1);
// }

// Ray------------------------------------------------------------------------------------------

Ray CreateRay(float3 origin, float3 direction, float3 localDirectionInCamera)
{
  Ray res = (Ray)0;
  res.origin = origin;
  res.direction = direction;
  res.localDirectionInCamera = localDirectionInCamera;
  res.energy = float3(1.0f, 1.0f, 1.0f);
  return res;
}

Ray CreateCameraRay(float2 undistortedNDC)
{
  // Transform the camera origin onto the world space.
  // it's provided with 
  // rayTracingShader.SetMatrix("_CameraToWorldMat", Camera.main.cameraToWorldMatrix);
  float3 cameraCurPixelInWorld = mul(_CameraToWorldMat, float4(0.0f, 0.0f, 0.0f, 1.0f)).xyz;

  // the forward direction in Opengl is -z beside it's +z 
  // so mind which graphics API are you using before perform the vector calculation
  //
  // for example, let's talk about the cross product.
  // it's usually being performed c = a x b where, in right-handed, a is the thumb, b is the index finger and c is the middle finger
  // in contrary, Unity performs inversely as in left-handed.
  //
  // However, this doesn't affect the projection matrix as Unity uses the Opengl convention for making a projection matrix.
  // so you consider z-flipping happens by the World to Camera Matrix of the camera.
  // This is the reason why Unity performs the same as opengl.
  
  // Invert the perspective projection of the view-space position.
  //float3 posInOpenGLCamera = mul(_CameraInverseProjection, float4(undistorted_ndc, 0.0f, 1.0f)).xyz; 
  // [ xnwn, ynwn, znwn, wn] = _Projection* ( xe, ye, ze, 1) 
	// Find (xe,ye,ze,1) corresponding to wn * (xn,yn, (-1), 1) 

  float3 posInOpenglCamera = mul(_CameraInverseProjection, float4(undistortedNDC, 0.0f, 1.0f)).xyz;
  float3 localDirectionInOpenglCamera = normalize(posInOpenglCamera);

  //float3 posInScreenSpace = mul(_Projection, float4(posInCamera, 1.0f)).xyz; 
	//debugging 
 
	//float3 myPosInCamera = float3(myxyNDC, -1); 
	//float3 myPosInScreenSpace = mul(_Projection, float4(myPosInCamera, 1.0f)).xyz; 
	//myDir = normalize(myDir); 
 
	// for debugging 
	//_IntersectionBuffer[id.y * width + id.x] = float4( normalize( posInCameraZero), 0); 
	//_RayDirectionBuffer[id.y * width + id.x] = float4( normalize( posInCameraMinusOne), 0); 
 
	//_EmissionBuffer[id.y * width + id.x] = float4( normalize( myPosInCamera), 0); 
	// _SpecularBuffer[id.y * width + id.x] = float4(myPosInCamera, 0);

  // Transform the direction from camera to world space and normalize.
  float3 dirInUnityWorld = mul(_CameraToWorldMat, float4(posInOpenglCamera, 0.0f)).xyz;
  float3 globalDirection = normalize(dirInUnityWorld);

  return CreateRay(cameraCurPixelInWorld, globalDirection, localDirectionInOpenglCamera);
}

RayHit CreateRayHit() {
  RayHit res = (RayHit)0;
  res.position = (float3)0;
  res.vertexUVs = (float3x2)0;
  res.distance = BIG_FLOAT;
  res.normal = (float3)0;
  res.uvInTriangle = (float2)0;  
  res.specular = (float3)0;
  res.emission = (float3)0;
  return res;
}

// Ray------------------------------------------------------------------------------------------

RayHit Collsion(Ray ray, int bounce, DomeData dome, PanoramaData panorama)
{
  RayHit resHit = CreateRayHit();
  
  if (bounce == 0)
  {
    IntersectDome(ray, resHit, dome);

    // Check the ray hits to the not-used-bottom area of Dome.
    // float3 rayvec = ray.direction * resHit.distance; // ray is a global vector in Unity World Space
    // float rayDistAlongCameraViewDir = dot(rayvec, _CameraViewDirectionInUnitySpace);
    // float penetrationDistIntoMirror = rayDistAlongCameraViewDir - dome.distance;
    
    // if (penetrationDistIntoMirror >= (1 - dome.maskingRatio) * dome.height)
    // {
    //   resHit.distance = BIG_FLOAT;
    // }
  } 
  else
  {
    IntersectMeshPanorama(ray, resHit, panorama);
  }
  return resHit;
}

float3 Shade(inout Ray ray, RayHit resHit) 
{
    float3 incidentVector = resHit.position - ray.origin;

    ray.origin = resHit.position + resHit.normal * 0.001;

    float3 reflectionVector = reflect(incidentVector, resHit.normal);
    //ray.direction = reflect(ray.direction, resHit.normal);
    ray.direction = normalize(reflectionVector);


  //ray.origin = resHit.position + resHit.normal * 0.001;
  //ray.direction = reflect(ray.direction, resHit.normal);
  //ray.energy *= resHit.specular;
  //
  if (resHit.emission.x < 0 && resHit.emission.y < 0 && resHit.emission.z < 0)
  {
    float2 uv = resHit.uvInTriangle;
    float2 uvTex = (1 - uv[0] - uv[1]) * resHit.vertexUVs[0]
                 + uv[0] * resHit.vertexUVs[1]
                 + uv[1] * resHit.vertexUVs[2];  
    return _PanoramaImage.SampleLevel(sampler_PanoramaImage, uvTex, 0).xyz;
  }
  else
  {
    return resHit.emission;
  } 
}


float3 PanoramaShade(inout Ray ray, RayHit resHit) 
{
  float3 incidentVector = resHit.position - ray.origin;

  ray.origin = resHit.position + resHit.normal * 0.001;

  float3 reflectionVector  = reflect(incidentVector, resHit.normal);
  //ray.direction = reflect(ray.direction, resHit.normal);
  ray.direction = normalize(reflectionVector);


  ray.energy *= resHit.specular;  

  // emission < -1 (It's panorama mesh for ray).
  if (resHit.emission.x < 0 && resHit.emission.y < 0 && resHit.emission.z < 0)
  {
      // TODO: Need to make selectable between ToRadialCoords and ToCubeCoords by the shape of panorama.
      // float2 tc = ToRadialCoords(resHit.xyzFromCenterOfPanoramaMesh);
      
      //SetPanoramaMappingParameters();

      // ray hits in the ceiling!
      
      // if (abs(resHit.xyzFromCenterOfPanoramaMesh.x) < 1.6)
      // { 
      //     return float3(0, 0, 0);
      // }

      float2 uv = ToPanoramaUV(resHit.xyzFromCenterOfPanoramaMesh);

      return _PanoramaImage.SampleLevel(sampler_PanoramaImage, uv, 0).xyz;
  }
  else
  {
      return resHit.emission;
  }
}//PanoramaShade

// vtx0, vtx1, vtx2 stays in the Unity Worldspace.
bool IntersectTriangle_MT97(Ray ray, float3 vtx0, float3 vtx1, float3 vtx2, out float t, out float u, out float v) 
{
  t = BIG_FLOAT;

  // find vectors for two edges sharing vertices.
  float3 edge1 = vtx1 - vtx0;
  float3 edge2 = vtx2 - vtx0;

  // begin calculating determinant - it's also used to calculate U param.
  // ray.direction is the direction in the Unity Worldspace.
  float3 pvec = cross(ray.direction, edge2);

  // if determinant is near zero, ray lies in plane of triangle.
  float det = dot(edge1, pvec);

  // use backface culling.
  if (abs(det) < EPS) 
  {
    return false;
  }

  float inv_det = 1.0 / det;

  // calculate distance from vertex0 to ray.origin.
  float3 tvec = ray.origin - vtx0;

  // calculate U param and test bounds.
  u = dot(tvec, pvec) * inv_det;

  if (u < 0.0 || u > 1.0) 
  {
    v = BIG_FLOAT;
    return false;
  }

  float3 qvec = cross(tvec, edge1);
  
  // prepare to test V param.
  v = dot(ray.direction, qvec) * inv_det;

  if (v < 0.0 || u + v > 1.0) 
  {
    return false;
  }
    
  // calculate t param, ray intersects on the triangle.
  t = dot(edge2, qvec) * inv_det;
  
  return true;
}

void IntersectMeshPanorama(Ray ray, inout RayHit bestHit, PanoramaData panorama) 
{
  uint offset = panorama.indexOffset;
  uint count = offset + panorama.indexCount;

  for (uint i = 0; i < count; i += 3) 
  {
    // get the current triangle defined by v0, v1 and v2
    float3 vtx0 = mul(panorama.localToWorld, float4(_Vertices[_Indices[i]], 1)).xyz;
    float3 vtx1 = mul(panorama.localToWorld, float4(_Vertices[_Indices[i + 1]], 1)).xyz;
    float3 vtx2 = mul(panorama.localToWorld, float4(_Vertices[_Indices[i + 2]], 1)).xyz;
    
    float3x2 texcoords = float3x2(_Texcoords[_Indices[i]],
                                  _Texcoords[_Indices[i + 1]],
                                  _Texcoords[_Indices[i + 2]]);
    
    float t = 0, u = 0, v = 0;    

    if (IntersectTriangle_MT97(ray, vtx0, vtx1, vtx2, t, u, v)) 
    {
      // find the nearest hit point.
      if (t > 0.0 && t < bestHit.distance) 
      {
        bestHit.distance = t;
        bestHit.position = ray.origin + t * ray.direction;
        bestHit.xyzFromCenterOfPanoramaMesh = bestHit.position - _centerOfPanoramaMesh.xyz;        
        bestHit.uvInTriangle = float2(u, v);
        bestHit.normal = normalize(cross(vtx1 - vtx0, vtx2 - vtx0));
        bestHit.vertexUVs = texcoords;
        bestHit.specular = panorama.specular; 
        bestHit.emission = panorama.emission;                 
      }
    }
  }  
}

void IntersectDome(Ray ray, inout RayHit resHit, DomeData dome)
{  
  float4x4 frame = dome.localToWorld; // this matrix is within the Unity Worldspace.
  float3 domePos = float3(frame[0][3], frame[1][3], frame[2][3]);
  float3 d = ray.origin - domePos;
  float p1 = -dot(ray.direction, d);
  float p2sqr = p1 * p1 - dot(d, d) + dome.radius * dome.radius;
  if (p2sqr < 0) 
      return;
  
  float p2 = sqrt(p2sqr);
  float t = p1 - p2 > 0 ? p1 - p2 : p1 + p2;
  
  if (t > 0 && t < resHit.distance) 
  {
    float3 hitVector = t * ray.direction;
    float hitDistAlongHemishereHeight = dot(hitVector, float3(0, -1, 0) ); // float3(0,0,-1) = the world down direction
    dbg_hitInfoBuf[0] = float4(hitDistAlongHemishereHeight, dome.distance, dome.height, 0.0);
    if (hitDistAlongHemishereHeight > (dome.distance + dome.height))
    {
      t = -1.0f; // no intersection with the usedPortion of the mirror
      return;
    }
    else
    {
      resHit.distance = t;
      resHit.position = ray.origin + t * ray.direction;
      resHit.normal = normalize(resHit.position - domePos);    
      resHit.specular = dome.specular;    
    }
  }
}

//ToPanoramaUV(resHit.position)
float2 ToPanoramaUV(float3 xyz) // xyz= vertex position -> uv coord 
{
	///////////////////////////////////////////////////////////////////
	// The hit position xyz was represented as a global position
    // It was converted to a local position relative to the center of the mesh, before it was passed
    // to this function

	 float3 normalizedxyz = normalize(xyz);
	
	 float latitude = asin(normalizedxyz.y);
     // asin(y) range: -PI/2 to PI/2
	
	 float longitude = atan2(normalizedxyz.z, normalizedxyz.x);
     // atan2 range : -PI ~ PI        평면상의 사분면을 판단
     // The range of longitude is two times as that of the latitude: The aspect of the panorama image
     // is 2:1
	//  uv should range from 0 to 1:
     float u = (longitude / PI) * 0.5 + 0.5; //u  ranges from 0 to 1;
     float v = (latitude / PI) + 0.5; // v ranges from 0 to 1
     //float2 uv = float2(longitude, latitude) * float2(0.5 / PI, 1.0 / PI); 
     float2 uv = float2(u, v);
	// new latitude  range : 1.0 - 0    = 1  ~  1.0 - 1   = 0  : 0 ~ 1
	// new longitude range : 0.5-(-0.5) = 1  ~  0.5 - 0.5 = 0  : 0 ~ 1
	//   return float2(0.5,1.0) - sphereCoords;  // == image coords corresponde to current vertex (0 ~ 1)
     return uv;
	
	/////////////////////////////////////////////////////////////////////////
	
}// ToPanoramaUV

float2 normalize(float x_u, float y_u, in CameraInternalData data) 
{
  float fx = data.FocalLengthX;
  float fy = data.FocalLengthY;
  float cx = data.PrincipalPointX;
  float cy = data.PrincipalPointY;

  // return float2(x_n, y_n).
  return float2((y_u - cy) / fy, (x_u - cx) / fx);
}

float2 denormalize(float x_u, float y_u, in CameraInternalData data) 
{
  float fx = data.FocalLengthX;
  float fy = data.FocalLengthY;
  float cx = data.PrincipalPointX;
  float cy = data.PrincipalPointY;

  float x_n = (x_u - cx) / fx; 
  float y_n = (y_u - cy) / fy;
  return float2(x_n, y_n);
}

float2 distort_normalized(float x_nu, float y_nu, in CameraInternalData data) 
{
  float k1 = data.RadialCoefficientX;
  float k2 = data.RadialCoefficientY;
  // k3 is in no use.

  float p1 = data.TangentialCoefficientX;
  float p2 = data.TangentialCoefficientY;

  float r2 = x_nu * x_nu + y_nu * y_nu;

  float radial_d = 1.0f +
                   (k1 * r2) +
                   (k2 * r2 * r2);

  float x_nd = (radial_d * x_nu) + 
               (2 * p1 * x_nu * y_nu) +
               (p2 * (r2 + 2 * x_nu * y_nu));

  float y_nd = (radial_d * y_nu) +
               (p1 * (r2 + 2 * y_nu * y_nu)) +
               (2 * p2 * x_nu * y_nu);
  return float2(x_nd, y_nd);
}

float2 undistortNDC_newton(float2 points, in CameraInternalData data)
{
  /*int i = 0;
    while (i < N) {
      i += 1;
      d = 1 + k1 * (s * s + t * t) + k2 * (s * s * s * s) + (2 * s * s * t * t) + (t * t * t * t);

      f1 = -u + (s * d + (2 * p1 * s * t + p2 * (s * s + t * t + 2 * s * s))) * fx * cx;
      f2 = -v + (t * d + (p1 * (s * s + t * t + 2 * t * t) + 2 * p2 * s * t)) * fy + cy;
      j1s = fx * (1 + k1 * (3 * s * s + t * t) + k2 * ((5 * s * s + 6 * t * t) * s * s + t * t * t * t)) + 2 * p1 * fx * t + 6 * p2 * fx * s;
      j1t = fx * (2 * k1 * s * t + 4 * k2 * (s * s * s * t + s * t * t * t)) + 2 * p1 * fx * s + 2 * p2 * fx * t;
      j2s = fy * (2 * k1 * s * t + 4 * k2 * (s * s * s * t + s * t * t * t)) + 2 * p1 * fy * s + 2 * p2 * fy * t;
      j2t = fy * (1 + k1 * (s * s + 3 * t * t) + 3 * t * t) + k2 * (s * s * s * s + (6 * s * s + 5 * t * t) * t * t)) + 6 * p1 * fy * t + 2 * p2 * fy * s;

      d = (j1s * j2t - j1t * j2s);

      S = s - (j2t * f1 - j1t * f2) / d;
      T = t - (j2s * f1 - j1s * f2) / d;

      if (abs(S - s) < err_threshold && abs(T - t) < err_threshold) {
        break;
      }

      s = S;
      t = T;
    }*/
  return (float2)0;
}

float2 undistortNDC_iterative(float2 points, in CameraInternalData data) 
{
  float2 p_nuInitialGuess = normalize(points.x, points.y, data);
  float2 p_nu = p_nuInitialGuess;
  int counter = 0;

  while (true) 
  {
    float2 err = distort_normalized(p_nu.x, p_nu.y, data);
    err -= p_nuInitialGuess;
    p_nu -= err;

    ++counter;
    if (counter >= (int)_IterativeSafeCounter) 
    {
      counter = 0;
      break;
    }

    if (err.x < _IterativeThreshold && err.y < _IterativeThreshold) 
    {
      break;
    }
  }

  float2 p_nu_denormalized = denormalize(p_nu.x, p_nu.y, data);
  return p_nu_denormalized;
}

float2 undistortNDC_direct(float2 points, CameraInternalData data) 
{
  // [points.x, points.y] = [fx_0, fy_0] * [xn_d, yn_d] + [cx, cy].
  float yn_d = (points.y - data.PrincipalPointY) / data.FocalLengthY;
  float xn_d = (points.x - data.PrincipalPointX) / data.FocalLengthX - yn_d;
  
  // distance = r ^ 2.
  float rsqr = xn_d * xn_d + yn_d * yn_d;
  // r ^ 4
  float r_u = rsqr * rsqr;

  float k1 = data.RadialCoefficientX;
  float k2 = data.RadialCoefficientY;
  float p1 = data.TangentialCoefficientX;
  float p2 = data.TangentialCoefficientY;

  float d1 = k1 * rsqr + k2 * r_u;
  float d2 = 1 / ((4 * k1 * rsqr) +
                 (6 * k2 * r_u) +
                 (8 * p1 * yn_d) +
                 (8 * p2 * xn_d + 1)); 

  float x_nu = xn_d - d2 * (d1 * xn_d) +
               (2 * p1 * xn_d * yn_d) +
               (p2 * (rsqr + 2 * xn_d * xn_d));

  float y_nu = yn_d - d2 * (d1 * yn_d) + 
               (2 * p2 * xn_d * yn_d) + 
               (p1 * (rsqr + 2 * yn_d * yn_d)); 

  float x_u = x_nu * data.FocalLengthX + data.PrincipalPointX;
  float y_u = y_nu * data.FocalLengthY + data.PrincipalPointY;

  // _Dbg_direct[0] = yn_d;
  // _Dbg_direct[1] = xn_d;
  // _Dbg_direct[2] = rsqr;
  // _Dbg_direct[3] = r_u;  
  // _Dbg_direct[4] = k1;
  // _Dbg_direct[5] = k2;
  // _Dbg_direct[6] = p1;
  // _Dbg_direct[7] = p2;
  // _Dbg_direct[8] = d1;
  // _Dbg_direct[9] = d2;
  // _Dbg_direct[10] = x_nu;
  // _Dbg_direct[11] = y_nu;
  // _Dbg_direct[12] = x_u;
  // _Dbg_direct[13] = y_u;
  
  return float2(x_u, y_u);
}

float2 calibrate(float2 coords, CameraInternalData dat)
{
  float fx = dat.FocalLengthX;
  float fy = dat.FocalLengthY;
  
  float cx = dat.PrincipalPointX;
  float cy = dat.PrincipalPointY;
  
  float k1 = dat.RadialCoefficientX; 
  float k2 = dat.RadialCoefficientY; 
  float k3 = dat.RadialCoefficientZ; 
  
  float p1 = dat.TangentialCoefficientX;
  float p2 = dat.TangentialCoefficientY;
  
  float skew_c = dat.SkewCoefficient;
  //  
  float y_nu = (coords.y - cy) / fy;
  float x_nu = (coords.x - cx) / fx; // - skew_c * y_nu;
  //
  float ru_2 = x_nu * x_nu + y_nu * y_nu;
  float radial_d = 1 + (k1 * ru_2) + (k2 * ru_2 * ru_2) + (k3 * ru_2 * ru_2 * ru_2);

  float x_nd = (radial_d * x_nu) + (2 * p1 * x_nu * y_nu) + p2 * (ru_2 + 2 * x_nu * y_nu);
  float y_nd = (radial_d * y_nu) + p1 * (ru_2 + 2 * y_nu * y_nu) + (2 * p2 * x_nu * y_nu);

  float x_pd = fx * (x_nd /* + skew_c * y_nd*/) + cx;
  float y_pd = fy * y_nd + cy;

  return float2(x_pd, y_pd);
}

// 
// A basic structure with modules
//

/*
    - 1 Kernal per 1 file.
    - Resources must be inside 1 file.
    - RayTracing Prerequisites <-> RayTracing Kernals.
    - Math Utilities.

    1. Resoures which are required for calibrating the camera distortion on projecting at runtime.

    struct CameraParams { ... };
    StructuredBuffer<CameraParams> _CameraParams;

    2. MeshObjects informations which are required for updating the ray-tracing scene data.

    .. Cone
    .. HalfSphere
    .. UFOHalfSphere
    .. Panorama (Cylinder)
    .. Panorama (Cube)

    + Basically All the mesh objects are provided with Space Transformation
    since ComputeShader doesn't have embedded functions and field.

    3. 1 Big POD-style Geometry to calculate ray-tracing and to draw all meshes in a frame.

    struct POD_MeshData {
      public List<Vector3> vertices;
      public List<int> indices;
      public List<Vector2> texcoords;
      public List<int> indices_offsets;
      public List<int> indices_counts;
      public List<Matrix4x4> local2Worlds;
      public List<Vector3> albedos;
      public List<Vector3> speculars;
      public List<Vector3> emissions;
      public List<float> smoothnesses;
    };

    4. Dbg part as an utility module

    5. Global Resources that helps to perform the shader.

    .. mostly they are matrices.
    .. camera properties.
*/
