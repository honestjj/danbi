#pragma kernel Dome_Reflector_Cube_Panorama
#pragma kernel Dome_Reflector_Cylinder_Panorama

static const float PI = 3.14159265f;
static const float EPS = 1e-8;
static const float BIG_FLOAT = 1e+8;

float4x4 _CameraToWorldMat;
float4x4 _Projection;
float4x4 _CameraInverseProjection;
float2 _PixelOffset;

Texture2D<float4> _PanoramaImage;
SamplerState sampler_PanoramaImage;

int _MaxBounce;
RWTexture2D<float4> _DistortedImage;

struct Ray 
{
  float3 origin;
  float3 direction;
  float3 localDirectionInCamera;
  float3 energy;
};

struct RayHit 
{
  float3 position; // hit position on the surface.
  float3 xyzInTriangle; // TODO:
  float2 uvInTriangle; // relative barycentric coords of the hit position.
  float3x2 vertexUVs;
  float distance;
  float3 normal; // normal at the ray hit position.
  float3 specular;
  float3 emission;
};

/*
* All geometries
*/
StructuredBuffer<float3> _Vertices;
StructuredBuffer<int> _Indices;
StructuredBuffer<float2> _Texcoords;

/*
* Undistortion methods
*/

int _UseUndistortion;
int _UndistortionMethod;
int _IterativeCounter;
int _IterativeSafeCounter;
int _IterativeThreshold;
int _NewtownThreshold;

/*
* Camera Internal Parameters
*/

struct CameraInternalData 
{
  float RadialCoefficientX;
  float RadialCoefficientY;
  float TangentialCoefficientX;
  float TangentialCoefficientY;
  float PrincipalPointX;
  float PrincipalPointY;
  float FocalLengthX;
  float FocalLengthY;
  float SkewCoefficient; // Rarely used recently since modern cameras have got better.
};
StructuredBuffer<CameraInternalData> _CameraInternalData;

/*
* Panorama 
*/
struct PanoramaData
{
  float high;
  float low;  
  float4x4 localToWorld;  
  float4x4 worldToLocal;
  int indexCount;
  int indexOffset;
  float3 specular;
  float3 emission;
};
StructuredBuffer<PanoramaData> _PanoramaData;

/*
* Halfsphere
*/
struct DomeData 
{  
  float distance;
  float height;
  float radius;
  float4x4 localToWorld;
  // float4x4 worldToLocal;
  int indexCount;  
  int indexOffset;
  float3 specular;
  float3 emission;
};
StructuredBuffer<DomeData> _DomeData;

//
// Panorama Coordinates Mapping
//
float4 _TexelSize;
float4 _FaceXCoordsLayouts;
float4 _FaceYCoordsLayouts;
float4 _FaceZCoordsLayouts;
float3 _Layout;
float4 _EdgeSize;

//
// Ray, RayHit
//
Ray CreateRay(float3 origin, float3 direction, float3 localDirectionInCamera);
Ray CreateCameraRay(float2 undistortedNDC);
RayHit CreateRayHit();

// Collision
RayHit Collsion(Ray ray, int bounce, DomeData shape, PanoramaData panorama);
// Shade
float3 Shade(inout Ray ray, RayHit resHit);
float3 PanoramaShade(inout Ray ray, RayHit resHit);

// Intersect
bool IntersectTriangle_MT97(Ray ray, float3 vtx0, float3 vtx1, float3 vtx2, out float t, out float u, out float v);
void IntersectDome(Ray ray, inout RayHit resHit, DomeData shape);
void IntersectMeshPanorama(Ray ray, inout RayHit bestHit, PanoramaData data);

float2 normalize(float x_u, float y_u, in CameraInternalData data);
float2 denormalize(float x_u, float y_u, in CameraInternalData data);
float2 distort_normalized(float x_nu, float y_nu, in CameraInternalData data);
float2 undistortNDC_newton(float2 p_d, in CameraInternalData data);
float2 undistortNDC_iterative(float2 p_d, in CameraInternalData data);
float2 undistortNDC_direct(float2 p_d, in CameraInternalData data);

float2 ToRadialCoords(float3 coords);
float2 ToCubeCoords(float3 coords, float3 layout, float4 edgeSize, float4 faceXCoordsLayouts, float4 faceYCoordsLayouts, float4 faceZCoordsLayout);

[numthreads(8, 8, 1)]
void Dome_Reflector_Cube_Panorama(uint3 id : SV_DispatchThreadID) 
{  
  float3 CameraPosInWorld = mul(_CameraToWorldMat, float4(0, 0, 0, 1)).xyz;
  float3 CameraViewDirection = -float3(_CameraToWorldMat[0][2], _CameraToWorldMat[1][2], _CameraToWorldMat[0][2]);
  
  uint width = 0, height = 0;
  _DistortedImage.GetDimensions(width, height);
  
  // float2 undistorted_ndc = float2(
  //   ((float)id.x + _PixelOffset.x) / (float)width * 2.0 - 1.0,
  //   ((float)id.y + _PixelOffset.y) / (float)height * 2.0 - 1.0
  // );
  float2 undistorted_ndc = (float2)0;

  if (_UseUndistortion == 0)
  { 
    undistorted_ndc = float2( 
      ((float)id.x + _PixelOffset.x) / ((float)width * 2.0 - 1.0), 
      ((float)id.y + _PixelOffset.y) / ((float)height * 2.0 - 1.0) 
    ); 
  } 
  else 
  { 
    float2 undistorted_pixelCoords = (float2)0;
 
    switch (_UndistortionMethod)
    { 
      case 0: 
      undistorted_pixelCoords = undistortNDC_direct((float2)id.xy, _CameraInternalData[0]); 
      break; 
 
      case 1: 
      undistorted_pixelCoords = undistortNDC_iterative((float2)id.xy, _CameraInternalData[0]); 
      break; 
 
      case 2: 
      undistorted_pixelCoords = undistortNDC_newton((float2)id.xy, _CameraInternalData[0]); 
      break;
    }

    undistorted_ndc = float2(undistorted_pixelCoords.x + _PixelOffset.x / (float)width * 2.0 - 1.0, 
                             undistorted_pixelCoords.y + _PixelOffset.y / (float)height * 2.0 - 1.0); 
  }  
  
  Ray ray = CreateCameraRay(undistorted_ndc);  
  RayHit resHit = (RayHit)0;
  
  // Black color is default.
  float3 totalCol = (float3)0;
  
  for (int i = 0; i < _MaxBounce; ++i) 
  {
    resHit = Collsion(ray, i, _DomeData[0], _PanoramaData[0]);
    
    if (resHit.distance >= BIG_FLOAT)
      break;
    
    totalCol += Shade(ray, resHit) * ray.energy;
    // totalCol += PanoramaShade(ray, resHit) * ray.energy;
    
    if (!any(ray.energy)) 
      break;
  }
  _DistortedImage[id.xy] = float4(totalCol, 1);
}

[numthreads(8, 8, 1)]
void Dome_Reflector_Cylinder_Panorama(uint3 id : SV_DispatchThreadID) 
{  
  float3 CameraPosInWorld = mul(_CameraToWorldMat, float4(0, 0, 0, 1)).xyz;
  float3 CameraViewDirection = -float3(_CameraToWorldMat[0][2], _CameraToWorldMat[1][2], _CameraToWorldMat[0][2]);
  
  uint width = 0, height = 0;
  _DistortedImage.GetDimensions(width, height);
  
  float2 undistorted_ndc = float2(
    ((float)id.x + _PixelOffset.x) / (float)width * 2.0 - 1.0,
    ((float)id.y + _PixelOffset.y) / (float)height * 2.0 - 1.0
  );
  
  Ray ray = CreateCameraRay(undistorted_ndc);  
  RayHit resHit = (RayHit)0;
  
  // Black color is default.
  float3 totalCol = (float3)0;
  
  for (int i = 0; i < _MaxBounce; ++i) 
  {
    resHit = Collsion(ray, i, _DomeData[0], _PanoramaData[0]);
    
    if (resHit.distance >= BIG_FLOAT)
      break;
    
    // totalCol += Shade(ray, resHit) * ray.energy;
    totalCol += PanoramaShade(ray, resHit) * ray.energy;
    
    if (!any(ray.energy)) 
      break;
  }
  _DistortedImage[id.xy] = float4(totalCol, 1);
}

// Ray------------------------------------------------------------------------------------------

Ray CreateRay(float3 origin, float3 direction, float3 localDirectionInCamera)
{
  Ray res = (Ray)0;
  res.origin = origin;
  res.direction = direction;
  res.localDirectionInCamera = localDirectionInCamera;
  res.energy = float3(1.0f, 1.0f, 1.0f);
  return res;
}

Ray CreateCameraRay(float2 undistortedNDC)
{
  // Transform the camera origin onto the world space.
  float3 cameraCurPixelInWorld = mul(_CameraToWorldMat, float4(0.0f, 0.0f, 0.0f, 1.0f)).xyz;

  // Invert the perspective projection of the view-space position.
  float3 posInCameraZero = mul(_CameraInverseProjection, float4(undistortedNDC, 0.0f, 1.0f)).xyz;
  float3 localDirectionInCamera = normalize(posInCameraZero);

  // Transform the direction from camera to world space and normalize.
  float3 dirInWorld = mul(_CameraToWorldMat, float4(posInCameraZero, 0.0f)).xyz;

  return CreateRay(cameraCurPixelInWorld, normalize(dirInWorld), localDirectionInCamera);
}

RayHit CreateRayHit() {
  RayHit res = (RayHit)0;
  res.position = (float3)0;
  res.vertexUVs = (float3x2)0;
  res.distance = BIG_FLOAT;
  res.normal = (float3)0;
  res.uvInTriangle = (float2)0;  
  res.specular = (float3)0;
  res.emission = (float3)0;
  return res;
}

// Ray------------------------------------------------------------------------------------------

RayHit Collsion(Ray ray, int bounce, DomeData dome, PanoramaData panorama)
{
  RayHit resHit = CreateRayHit();
  
  if (bounce == 0)
  {
    IntersectDome(ray, resHit, dome); 
  } 
  else
  {
    IntersectMeshPanorama(ray, resHit, panorama);
  }
  return resHit;
}

float3 Shade(inout Ray ray, RayHit resHit) 
{
  ray.origin = resHit.position + resHit.normal * 0.001;
  ray.direction = reflect(ray.direction, resHit.normal);
  ray.energy *= resHit.specular;
  
  if (resHit.emission.x < 0 && resHit.emission.y < 0 && resHit.emission.z < 0)
  {
    float2 uv = resHit.uvInTriangle;
    float2 uvTex = (1 - uv[0] - uv[1]) * resHit.vertexUVs[0]
                 + uv[0] * resHit.vertexUVs[1]
                 + uv[1] * resHit.vertexUVs[2];  
    return _PanoramaImage.SampleLevel(sampler_PanoramaImage, uvTex, 0).xyz;
  }
  else
  {
    return resHit.emission;
  } 
}

void SetPanoramaMappingParameters()
{
  uint width = 0, height = 0;
  _DistortedImage.GetDimensions(width, height);

  _TexelSize = float4(1.0 / width, 1.0 / height, width, height);

  float sourceAspect = float(_TexelSize.z) / float(_TexelSize.w);
  bool3 aspectTest = sourceAspect > float3(1.0,
							                             1.0f / 6.0f + (3.0f / 4.0f - 1.0f / 6.0f) / 2.0f,
							                             6.0f / 1.0f + (4.0f / 3.0f - 6.0f / 1.0f) / 2.0f);
  if (aspectTest[0]) // horizontal
	{
		if (aspectTest[2])
		{ // horizontal strip
			_FaceXCoordsLayouts = float4(0.5,0.5,1.5,0.5); // x축면의 좌표
			_FaceYCoordsLayouts = float4(2.5,0.5,3.5,0.5);
			_FaceZCoordsLayouts = float4(4.5,0.5,5.5,0.5);
			_Layout = float3(-1, 1.0 / 6.0, 1.0 / 1.0); // x : bool -> 세로 교차 레이아웃 표시, yz : 정규화 좌표를 텍스쳐 좌표로 조정하기 위한 값
		}
		else
		{ // horizontal cross
			_FaceXCoordsLayouts = float4(2.5,1.5,0.5,1.5);
			_FaceYCoordsLayouts = float4(1.5,2.5,1.5,0.5);
			_FaceZCoordsLayouts = float4(1.5,1.5,3.5,1.5);
			_Layout = float3(-1, 1.0 / 4.0, 1.0 / 3.0);
		}
	}
	else
	{
		if (aspectTest[1])
		{ // vertical cross
			_FaceXCoordsLayouts = float4(2.5,2.5,0.5,2.5);
			_FaceYCoordsLayouts = float4(1.5,3.5,1.5,1.5);
			_FaceZCoordsLayouts = float4(1.5,2.5,1.5,0.5);
			_Layout = float3(1, 1.0 / 3.0, 1.0 / 4.0);
		}
		else
		{ // vertical strip
			_FaceXCoordsLayouts = float4(0.5,5.5,0.5,4.5);
			_FaceYCoordsLayouts = float4(0.5,3.5,0.5,2.5);
			_FaceZCoordsLayouts = float4(0.5,1.5,0.5,0.5);
			_Layout = float3(-1, 1.0 / 1.0, 1.0 / 6.0);
		}
	}    

  _EdgeSize.xy = _TexelSize.xy * 0.5 / _Layout.yz - 0.5;
  _EdgeSize.zw = -_EdgeSize.xy;
}

float3 PanoramaShade(inout Ray ray, RayHit resHit) 
{
  ray.origin = resHit.position + resHit.normal * 0.001;
  ray.direction = reflect(ray.direction, resHit.normal);
  ray.energy *= resHit.specular;  

  // TODO: Need to make selectable between ToRadialCoords and ToCubeCoords by the shape of panorama.
  // float2 tc = ToRadialCoords(resHit.xyzInTriangle);
  SetPanoramaMappingParameters();                                 
  float2 tc = ToCubeCoords(resHit.xyzInTriangle, _Layout, _EdgeSize, _FaceXCoordsLayouts, _FaceYCoordsLayouts, _FaceZCoordsLayouts);
  return _PanoramaImage.SampleLevel(sampler_PanoramaImage, tc, 0).xyz;
}

bool IntersectTriangle_MT97(Ray ray, float3 vtx0, float3 vtx1, float3 vtx2, out float t, out float u, out float v) 
{
  t = BIG_FLOAT;

  // find vectors for two edges sharing vertices.
  float3 edge1 = vtx1 - vtx0;
  float3 edge2 = vtx2 - vtx0;

  // begin calculating determinant - it's also used to calculate U param.
  float3 pvec = cross(ray.direction, edge2);

  // if determinant is near zero, ray lies in plane of triangle.
  float det = dot(edge1, pvec);

  // use backface culling.
  if (abs(det) < EPS) 
  {
    return false;
  }

  float inv_det = 1.0 / det;

  // calculate distance from vertex0 to ray.origin.
  float3 tvec = ray.origin - vtx0;

  // calculate U param and test bounds.
  u = dot(tvec, pvec) * inv_det;

  if (u < 0.0 || u > 1.0) 
  {
    v = BIG_FLOAT;
    return false;
  }

  float3 qvec = cross(tvec, edge1);
  
  // prepare to test V param.
  v = dot(ray.direction, qvec) * inv_det;

  if (v < 0.0 || u + v > 1.0) 
  {
    return false;
  }
    
  // calculate t param, ray intersects on the triangle.
  t = dot(edge2, qvec) * inv_det;
  
  return true;
}

void IntersectMeshPanorama(Ray ray, inout RayHit bestHit, PanoramaData panorama) 
{
  uint offset = panorama.indexOffset;
  uint count = offset + panorama.indexCount;

  for (uint i = 0; i < count; i += 3) 
  {
    // get the current triangle defined by v0, v1 and v2
    float3 vtx0 = mul(panorama.localToWorld, float4(_Vertices[_Indices[i]], 1)).xyz;
    float3 vtx1 = mul(panorama.localToWorld, float4(_Vertices[_Indices[i + 1]], 1)).xyz;
    float3 vtx2 = mul(panorama.localToWorld, float4(_Vertices[_Indices[i + 2]], 1)).xyz;
    
    float3x2 texcoords = float3x2(_Texcoords[_Indices[i]],
                                  _Texcoords[_Indices[i + 1]],
                                  _Texcoords[_Indices[i + 2]]);
    
    float t = 0, u = 0, v = 0;    

    if (IntersectTriangle_MT97(ray, vtx0, vtx1, vtx2, t, u, v)) 
    {
      // find the nearest hit point.
      if (t > 0.0 && t < bestHit.distance) 
      {
        bestHit.distance = t;
        bestHit.position = ray.origin + t * ray.direction;
        bestHit.uvInTriangle = float2(u, v);
        bestHit.normal = normalize(cross(vtx1 - vtx0, vtx2 - vtx0));
        bestHit.vertexUVs = texcoords;
        bestHit.xyzInTriangle = mul(panorama.worldToLocal, float4(bestHit.position, 1)).xyz;
        bestHit.specular = panorama.specular; 
        bestHit.emission = panorama.emission;          
      }
    }
  }
}

void IntersectDome(Ray ray, inout RayHit resHit, DomeData dome)
{
  float4x4 frame = dome.localToWorld;
  float3 domePos = float3(frame[0][3], frame[1][3], frame[2][3]);
  float3 d = ray.origin - domePos;
  float p1 = -dot(ray.direction, d);
  float p2sqr = p1 * p1 - dot(d, d) + dome.radius * dome.radius;
  if (p2sqr < 0) 
      return;
  
  float p2 = sqrt(p2sqr);
  float t = p1 - p2 > 0 ? p1 - p2 : p1 + p2;
  
  if (t > 0 && t < resHit.distance) 
  {
    resHit.distance = t;
    resHit.position = ray.origin + t * ray.direction;
    resHit.normal = normalize(resHit.position - domePos);    
    resHit.specular = dome.specular;
    // TODO: Do I need to pass the emission to RayHit?
    // resHit.emission = dome.emission;
  }
}

float2 ToRadialCoords(float3 coords) // coords -> 3d coords vertex 
{
	/////////////////////////////////////////////////////////////////////
	//
	//         float3 normalizedCoords = normalize(coords);
	//// acos range : 0 ~ PI           높이를 기준으로 각도를 구함 y : 0 -> 북극 1 -> 남극
	//// acos(1) = 0
	//// acos(0) = PI / 2
	//// acos(-1) = PI
	//   float latitude = acos(normalizedCoords.y); 
	//// atan2 range : -PI ~ PI        평면상의 사분면을 판단
	//   float longitude = atan2(normalizedCoords.z, normalizedCoords.x); 
	//// latitude / PI         //  latitude  range :    0 ~ 1
	//         // longitude * 0.5 / PI  //  longitude range : -0.5 ~ 0.5 
	//	 float2 sphereCoords = float2(longitude, latitude) * float2(0.5 / UNITY_PI, 1.0 / UNITY_PI); 
	//// new latitude  range : 1.0 - 0    = 1  ~  1.0 - 1   = 0  : 0 ~ 1
	//// new longitude range : 0.5-(-0.5) = 1  ~  0.5 - 0.5 = 0  : 0 ~ 1
	//   return float2(0.5,1.0) - sphereCoords;  // == image coords corresponde to current vertex (0 ~ 1)
	//
	///////////////////////////////////////////////////////////////////////////
	// if Cylinder Origin Point is not center of Mesh then adjust the coords of Mesh Y value.
	float3 sphereCoords = (float3)0;
	float3 cylinderCoords = coords;
	//float Cylinder_r, Cylinder_h, Cylinder_phi;
	//float Sphere_r, Sphere_theta, Sphere_phi;
	//// cylinderCoords.x = r
	//// cylinderCoords.y = h
	//// cylinderCoords.z = phi
	//Cylinder_r = sqrt(pow(coords.x, 2) + pow(coords.z, 2));
	//Cylinder_h = coords.y;
	//Cylinder_phi = acos(coords.x / Cylinder_
	//Sphere_r = Cylinder_r;
	//Sphere_theta = atan2(Cylinder_h, Cylinder_r);
	//Sphere_phi = Cylinder_p
	//// x = rcos(theta) * cos(phi)
	//// y = rsin(theta)
	//// z = rcos(theta) * sin(phi)
	//sphereCoords.x = Sphere_r * cos(Sphere_theta) * cos(Sphere_phi);
	//sphereCoords.y = Sphere_r * sin(Sphere_theta);
	//sphereCoords.z = Sphere_r * cos(Sphere_theta) * sin(Sphere_ph
	//coords.y -= _CylinderHeight * 0.
	// Translate vertex of Cylinder coords to vertex of Sphere coords 
	
	//Change the ratio of x and z by the amount of change in y
  float _CylinderRadius = 0.5;
	if (abs(cylinderCoords.y) > 0.01)
	{
		sphereCoords.y = sin(atan2(cylinderCoords.y, _CylinderRadius)); // 1 for x
		sphereCoords.x = cylinderCoords.x * sphereCoords.y / cylinderCoords.y;
		sphereCoords.z = cylinderCoords.z * sphereCoords.y / cylinderCoords.y;
	}

  if (sphereCoords.x == 0 || sphereCoords.y == 0 || sphereCoords.z == 0) 
  {
    return float2(0.0, 0.0);
  }

	float3 normalizedcoords = normalize(sphereCoords);
	// acos range : 0 ~ pi           높이를 기준으로 각도를 구함 y : 0 -> 북극 1 -> 남극
	// acos(1) = 0
	// acos(0) = pi / 2
	// acos(-1) = pi
	float latitude = acos(normalizedcoords.y); 
	// atan2 range : -pi ~ pi        평면상의 사분면을 판단
	float longitude = atan2(normalizedcoords.z, normalizedcoords.x); 
	// latitude / pi         //  latitude  range :    0 ~ 1
	// longitude * 0.5 / pi  //  longitude range : -0.5 ~ 0.5  
	float2 spherecoords = float2(longitude, latitude) * float2(0.5 / PI, 1.0 / PI);
	// new latitude  range : 1.0 - 0    = 1  ~  1.0 - 1   = 0  : 0 ~ 1
	// new longitude range : 0.5-(-0.5) = 1  ~  0.5 - 0.5 = 0  : 0 ~ 1
	return float2(0.5,1.0) - spherecoords;  // == image coords corresponde to current vertex (0 ~ 1)
}

float2 ToCubeCoords(float3 coords, float3 layout, float4 edgeSize, float4 faceXCoordsLayouts, float4 faceYCoordsLayouts, float4 faceZCoordsLayouts)
{
  // Determine the primawry axis of the normal.
  float3 absN = abs(coords);
  float3 absDir = absN > float3(max(absN.y, absN.z), max(absN.x, absN.z), max(absN.x, absN.y)) ? 1 : 0;

  // Convert the normal to a local face texture coordinates [-1, 1], note that tcAndLen.z == dot(coords, absDir);
  // and thus its sign tells us whether the normal is pointing positive or negative.abort
  float3 tcAndLen = mul(absDir, float3x3(coords.zyx, coords.xzy, float3(-coords.xy, coords.z)));
  // TODO: divided by zero temp blocking.
  if (tcAndLen.z == 0.0)
  {
    return float2(0.0, 0.0);
  }

  tcAndLen.xy /= tcAndLen.z;
  // put the faces inside out for proper orientation and normalize to [-0.5, 0.5]
  bool2 positiveAndVCross = float2(tcAndLen.z, layout.x) > 0;
  tcAndLen.xy *= (positiveAndVCross[0] ? absDir.yx : (positiveAndVCross[1] ? float2(absDir[2], 0) : float2(0, absDir[2]))) - 0.5;
  // clamp the values which are close to the face edges to avoid bleeding/seams (e.g. enforce clamp texture wrap mode)
  tcAndLen.xy = clamp(tcAndLen.xy, edgeSize.xy, edgeSize.zw);
  // scale and offset the texture coords to mathc the proper squar in the exture based on Layout.
  float4 coordsLayout = mul(float4(absDir, 0), float4x4(faceXCoordsLayouts, faceYCoordsLayouts, faceZCoordsLayouts, faceZCoordsLayouts));
  tcAndLen.xy = (tcAndLen.xy + (positiveAndVCross[0] ? coordsLayout.xy : coordsLayout.zw)) * layout.yz;
  return tcAndLen.xy;
}

float2 normalize(float x_u, float y_u, in CameraInternalData data) 
{
  float fx = data.FocalLengthX;
  float fy = data.FocalLengthY;
  float cx = data.PrincipalPointX;
  float cy = data.PrincipalPointY;

  // return float2(x_n, y_n).
  return float2((y_u - cy) / fy, (x_u - cx) / fx);
}

float2 denormalize(float x_u, float y_u, in CameraInternalData data) 
{
  float fx = data.FocalLengthX;
  float fy = data.FocalLengthY;
  float cx = data.PrincipalPointX;
  float cy = data.PrincipalPointY;

  float x_n = (x_u - cx) / fx; 
  float y_n = (y_u - cy) / fy;
  return float2(x_n, y_n);
}

float2 distort_normalized(float x_nu, float y_nu, in CameraInternalData data) 
{
  float k1 = data.RadialCoefficientX;
  float k2 = data.RadialCoefficientY;
  // k3 is in no use.

  float p1 = data.TangentialCoefficientX;
  float p2 = data.TangentialCoefficientY;

  float r2 = x_nu * x_nu + y_nu * y_nu;

  float radial_d = 1.0f +
                   (k1 * r2) +
                   (k2 * r2 * r2);

  float x_nd = (radial_d * x_nu) + 
               (2 * p1 * x_nu * y_nu) +
               (p2 * (r2 + 2 * x_nu * y_nu));

  float y_nd = (radial_d * y_nu) +
               (p1 * (r2 + 2 * y_nu * y_nu)) +
               (2 * p2 * x_nu * y_nu);
  return float2(x_nd, y_nd);
}

float2 undistortNDC_newton(float2 p_d, in CameraInternalData data)
{
  /*int i = 0;
    while (i < N) {
      i += 1;
      d = 1 + k1 * (s * s + t * t) + k2 * (s * s * s * s) + (2 * s * s * t * t) + (t * t * t * t);

      f1 = -u + (s * d + (2 * p1 * s * t + p2 * (s * s + t * t + 2 * s * s))) * fx * cx;
      f2 = -v + (t * d + (p1 * (s * s + t * t + 2 * t * t) + 2 * p2 * s * t)) * fy + cy;
      j1s = fx * (1 + k1 * (3 * s * s + t * t) + k2 * ((5 * s * s + 6 * t * t) * s * s + t * t * t * t)) + 2 * p1 * fx * t + 6 * p2 * fx * s;
      j1t = fx * (2 * k1 * s * t + 4 * k2 * (s * s * s * t + s * t * t * t)) + 2 * p1 * fx * s + 2 * p2 * fx * t;
      j2s = fy * (2 * k1 * s * t + 4 * k2 * (s * s * s * t + s * t * t * t)) + 2 * p1 * fy * s + 2 * p2 * fy * t;
      j2t = fy * (1 + k1 * (s * s + 3 * t * t) + 3 * t * t) + k2 * (s * s * s * s + (6 * s * s + 5 * t * t) * t * t)) + 6 * p1 * fy * t + 2 * p2 * fy * s;

      d = (j1s * j2t - j1t * j2s);

      S = s - (j2t * f1 - j1t * f2) / d;
      T = t - (j2s * f1 - j1s * f2) / d;

      if (abs(S - s) < err_threshold && abs(T - t) < err_threshold) {
        break;
      }

      s = S;
      t = T;
    }*/
  return (float2)0;
}

float2 undistortNDC_iterative(float2 p_d, in CameraInternalData data) 
{
  float2 p_nuInitialGuess = normalize(p_d.x, p_d.y, data);
  float2 p_nu = p_nuInitialGuess;

  while (true) 
  {
    float2 err = distort_normalized(p_nu.x, p_nu.y, data);
    err -= p_nuInitialGuess;
    p_nu -= err;

    ++_IterativeCounter;
    if (_IterativeCounter >= _IterativeSafeCounter) 
    {
      _IterativeCounter = 0;
      break;
    }

    if (err.x < _IterativeThreshold && err.y < _IterativeThreshold) 
    {
      break;
    }
  }

  float2 p_nu_denormalized = denormalize(p_nu.x, p_nu.y, data);
  return p_nu_denormalized;
}

float2 undistortNDC_direct(float2 p_d, in CameraInternalData data) 
{
  // [p_d.x, p_d.y] = [fx_0, fy_0] * [xn_d, yn_d] + [cx, cy].
  float xn_d = (p_d.x - data.PrincipalPointX) / data.FocalLengthX;
  float yn_d = (p_d.y - data.PrincipalPointY) / data.FocalLengthY;
  // distance = r ^ 2.
  float rsqr = xn_d * xn_d + yn_d * yn_d;
  // r ^ 4
  float rqd = rsqr * rsqr;

  float k1 = data.RadialCoefficientX;
  float k2 = data.RadialCoefficientY;
  float p1 = data.TangentialCoefficientX;
  float p2 = data.TangentialCoefficientY;
  
  float d1 = k1 * rsqr + k2 * rqd;
  float d2 = (4 * k1 * rsqr) + (6 * k2 * rqd) + (8 * p1 * yn_d) + (8 * p2 * xn_d + 1); 
  d2 = 1 / d2;

  float xn_u = xn_d - d2 * (d1 * xn_d) +
               (2 * p1 * xn_d * yn_d) +
               (p2 * (rsqr + 2 * xn_d * xn_d));

  float yn_u = yn_d - d2 * (d1 * yn_d) + 
               (2 * p2 * xn_d * yn_d) + 
               (p1 * (rsqr + 2 * yn_d * yn_d)); 

  float x_u = xn_u * data.FocalLengthX + data.PrincipalPointX;
  float y_u = yn_u * data.FocalLengthY + data.PrincipalPointY;
  return float2(x_u, y_u);
}

// 
// A basic structure with modules
//

/*
    - 1 Kernal per 1 file.
    - Resources must be inside 1 file.
    - RayTracing Prerequisites <-> RayTracing Kernals.
    - Math Utilities.

    1. Resoures which are required for calibrating the camera distortion on projecting at runtime.

    struct CameraParams { ... };
    StructuredBuffer<CameraParams> _CameraParams;

    2. MeshObjects informations which are required for updating the ray-tracing scene data.

    .. Cone
    .. HalfSphere
    .. UFOHalfSphere
    .. Panorama (Cylinder)
    .. Panorama (Cube)

    + Basically All the mesh objects are provided with Space Transformation
    since ComputeShader doesn't have embedded functions and field.

    3. 1 Big POD-style Geometry to calculate ray-tracing and to draw all meshes in a frame.

    struct POD_MeshData {
      public List<Vector3> vertices;
      public List<int> indices;
      public List<Vector2> texcoords;
      public List<int> indices_offsets;
      public List<int> indices_counts;
      public List<Matrix4x4> local2Worlds;
      public List<Vector3> albedos;
      public List<Vector3> speculars;
      public List<Vector3> emissions;
      public List<float> smoothnesses;
    };

    4. Dbg part as an utility module

    5. Global Resources that helps to perform the shader.

    .. mostly they are matrices.
    .. camera properties.
*/
